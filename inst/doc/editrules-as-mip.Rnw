%\VignetteIndexEntry{Error localization for numerical and categorical edits as a mixed integer problem}
\documentclass[11pt, fleqn, a4paper]{article}
\usepackage[english]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{threeparttable}
\usepackage{mySweave}
\usepackage{natbib}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\usepackage{threeparttable}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\Lor}{\lor}
\DeclareMathOperator*{\Land}{\land}
\DeclareMathOperator{\res}{\mathfrak{R}}
\newcommand{\rhomap}{\xrightarrow{\rho}}

\newtheorem{theorem}{Theorem}

\usepackage{float} 
 
\floatstyle{boxed}
\newfloat{Rcode}{t}{rco}
\floatname{Rcode}{Figure}



% stimulate latex to put multiple floats on a page.
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{3}
\setcounter{dbltopnumber}{2}
\renewcommand{\topfraction}{.9}
\renewcommand{\textfraction}{.1}
\renewcommand{\bottomfraction}{.75}
\renewcommand{\floatpagefraction}{.9}
\renewcommand{\dblfloatpagefraction}{.9}
\renewcommand{\dbltopfraction}{.9}
\hyphenation{time-stamp}

<<echo=false>>=
library(editrules)
@

\title{Error localization as a mixed integer problem with the {\tt editrules} package\\
{\small package version \Sexpr{packageVersion("editrules")}}}
\author{Edwin de Jonge and Mark van der Loo}
\begin{document}
\maketitle
\begin{abstract}
{\em This vignette is far from finished. Version 2.0 of the package will have
the full vignette. At the moment, functionality for solving error localization problems
with lp solvers is experimental.}
\end{abstract}

\newpage
\tableofcontents
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SECTION 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
Analyses of real data are often hindered by occurrences of incomplete or
inconsistent raw data records.  The process of locating and correcting such
errors is referred to as {\em data editing}, and it has been estimated that
National Statistics Institutes spend up to 40\% of their resources on this
process \citep{waal:2011}. For this reason, considerable attention is paid to
the development of data editing methods that can be automated. Since data are
often required to obey many interrelated consistency rules, data
editing can be too complex to perform manually. \citet{winkler:1999} mentions
practical cases where records have to obey 250, 300 or even 750 internal
consistency rules.  Although the {\sf R} statistical environment has numerous
facilities for analyzing categorical data [See {\em e.g.} \citet{husson:2010}],
the options for error localization and record correction are currently limited.

The {\sf R} package {\sf editrules} was
developed to help closing the gap between raw data retrieval and data analysis
with {\sf R}.  The main purpose of the {\sf editrules} package is to provide a
user-friendly environment for handling data restriction rules, to apply those
rules to data, and to localize erroneous fields in data based on the
generalized principle of \cite{fellegi:1976}.  The package does not offer
functionality for data correction. However, it does facilitate the
identification of the set of solutions for an error correction problem. 
For a detailed description we refer to \cite{jonge:2011} and \cite{loo:2011b}.

{\sf editrules} offers a fairly complete toolbox to work with numerical and 
categorical edits. It contains a flexible object for localizing errors, which 
can be adapted by the user of {\sf editrules} based on a branch and bound
algorithm \citep{waal:2011}. However, for the time to solve the error 
localization problem with a branch and bound algorithm grows exponentially 
with the number of (incorrect) variables. Many surveys have hundreds of variables, 
which results in (very) long processing times for records with many errors. 

This paper describes the error localization problem for numerical and categorical 
edits as a mixed integer problem and its implementation in {\sf editrules}. A brief 
description can be found in \citep{waal:2011} p. 75.
Mixed integer programming is a special case of linear programming. Linear 
programming maximizes a linear objective function, which is subject to linear
equality and linear inequality constraints. More formally: 
\begin{eqnarray}
\label{eq:mip}
   \textrm{Maximize } {\bf c}^T {\bf x} \\
   A {\bf x} \leq {\bf b} \\
   \textrm{with } {\bf x} \geq 0
\end{eqnarray}
where ${\bf x}$ is the vector of (numerical) variables to be optimized, ${\bf c}$ is a vector of weights, ${\bf b}$ is a vector of upper bounds and $A$ is a coefficient matrix for the constraints. In mixed integer programming (mip) ${\bf x}$ is a mixture of continious and integer variables.

Error localization implemented as a mixed integer programming results in a fast procedure, which is typically much faster than the branch and bound method also available in {\sf editrules}.

In section \ref{sec:numdataerror} we describe a mip formulation for numerical records. Section ref describes the mip formulation for categorical records. We end with a discussion on the implementation in {\sf editrules}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SECTION 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Numerical data errors}
\label{sec:numdataerror}
A numerical record $\bf x$  with reported values $({x^0_1,\dots,x^0_m)}$ has the following linear constraints:
\begin{equation}
\label{eq:edit}
A {\bf x \odot b} \textrm{ with }\odot\in\{<,\leq,=\}^n,
\end{equation}

It can easily be checked with {\sf editrules} if $\bf x$ violates any of these constraints. If this is the
case, the task is to find the minimal (weighted) number of adjustments to the reported values such that it
complies to the edits. These edits are (usually) valid for all records of a data set. 
For each reported record we define a seperate mip, which contains the set of edits extended with edits 
that depend on the reported values.

In practice reported values are always bounded: No person is older than 200 years old or taller than 30 feet. So each for each variable $x_i$  we assume a lower boundary $\rm l_i$ and an upper boundary $\rm u_i$\footnote{Note that equation \ref{eq:boundary} can also be written in the form of \ref{eq:edit}. We will use univariate or boundary constraints explicitly and exclude them from \ref{eq:edit}.}.
\begin{equation}
{\rm l}_i \leq x_i \leq {\rm u}_i \label{eq:boundary}
\end{equation}

For each $x_i$ we introduce a binary variable $\Delta_i \in \{0,1\}$:
\begin{equation} \label{eq:delta}
  \Delta_i = \left\{ 
  \begin{array}{ll}
         0 & \mbox{$if x_i = x^0_i$} \\
         1 & \mbox{$if x_i \neq x^0_i$}.
  \end{array} \right. 
\end{equation}
where $x^0_i$ is the reported value for $x_i$. We now add the following edits to the edit set: 

\begin{equation} \label{eq:binconstraint}
 ({\rm l}_i - x^0_i)\Delta_i + x^0_i  \leq   x_i  \leq x^0_i + ({\rm u}_i - x^0_i)\Delta_i 
\end{equation}

It can easily be checked that if $\Delta_i = 0$ these edits reduce to $x_i = x^0_i$, meaning
that the reported $x^0_i$ is assumed correct. If $\Delta_i = 1$ the edits 
reduce to equation \ref{eq:boundary}, meaning that the value of $x_i$ can take any feasible value within 
its boundaries $\rm l_i$ and $\rm u_i$.

Using principle of Felligi Holt \citep{fellegi:1976} which minimizes the weigthed sum of adaptations, the error localization problem can be written as:

{\textrm Minimize} $\sum^m_{j=1} {\rm w_j}\Delta_j$, with:
\begin{equation}
\label{eq:nummip}
\begin{array}{rcrcl}
\sum^m_{j=1} a_{1j} x_j &&                  &\odot_1& b_1    \\
\ldots                 &&                  &\ldots& \ldots  \\
\sum^m_{j=1}a_{nj} x_j &&                  &\odot_n& b_n    \\
    x_1 &-& ({\rm u_1 -  x^0_1}) \Delta_1   &\leq   & x^0_1 \\
   -x_1 &+& ({\rm l_1} - x^0_1) \Delta_1  &\leq   & -x^0_1 \\
\ldots  & & \ldots          &       & \ldots \\
    x_m &-& ({\rm u_m} - x^0_m) \Delta_m   &\leq   & x^0_m \\
   -x_m &+& ({\rm l_m} - x^0_m) \Delta_m  &\leq   & -x^0_m

\end{array}
\end{equation}
with $\rm w_j$ a weight for variable $x_j$. This problem is equal to the following mixed integer problem:

$$
\begin{array}{rcl}
   \mbox{Maximize } {\bf c}^T {\bf \hat{x}} \\
   \hat{A} {\bf \hat{x}} & \leq & {\bf \hat{b}} \\
   \textrm{with } {\bf \hat{x}} & \geq & 0 \\
   {\bf \hat{x}} & = &(x_1 - {\rm l_1}, \ldots, x_m - {\rm l_m}, \Delta_1, \ldots, \Delta_m) \\
   {\bf c} & = & (0, \ldots, 0, -{\rm w_1}, \ldots, -{\rm w_m}) \\
   {\bf \hat{b}} & = & (b_1, \ldots, b_m, x^0_1, -x^0_1, \ldots, x^0_m, -x^0_m)
\end{array}
$$

\subsection{Boundaries}
The extended edit set derived in (\ref{eq:nummip}) depends on the boundaries $\rm l_i$ and 
$\rm u_i$. Mathematically the size of these coefficients does not matter. Computationally however their
size is important. If any $|{\rm u_i - c_i}| \gg |a_j|$ or $|{\rm l_i - c_i}| \gg |a_j|$ the resulting mixed integer program may become numerical
unstable. From the lpsolve manual \citep{lpsolveman:2012}:

\begin{quote}
The chance for numerical instability and rounding errors is considerably larger when the input data contains both large and small numbers. So to improve stability, one must try to work with numbers that are somewhat in the same range. Ideally in the neighbourhood of 1.\\

You should realize, that you the user are probably in a better position to scale the problem than any computer algorithm. 
\end{quote}

For the error localization problem this means that the upper and lower boundaries of variables $x_i$ 
shouldn't be too large. A reasonable approach is to take the minimum and maximum values for all variables 
in a dataset and multiply them with a factor $f$ (e.g. $1000$).

\subsection{Implementation in {\sf editrules}}
{\sf editrules} contains the function {\sf localizeErrors} which can be used to localize errors in a {\tt data.frame}. It default implemention using a branch and bound algorithm is described in detail in \citep{jonge:2011}. It accepts an {\sf editmatrix} and a {\sf
data.frame}, and returns an object of class {\sf errorLocation}. An {\sf
errorLocation} object contains the locations of errors for each record in the
{\sf data.frame} as well as logging information, solution weights and
degeneracy. 

We extended this function with a parameter {\tt method}, that can be used to select the {\tt 
localizer} or {\tt mip} method. If the method "mip" is given, {\sf editrules} internally creates for each 
record an extended {\sf editmatrix} {\tt E} that contains the conditional boundary conditions as defined 
in (\ref{eq:nummip}). Internally the package \cite{lpSolveAPI:2011} is used to solve the resulting mixed integer program.
%


Figure \ref{RlocalizeErrors} shows an example of localizing errors using mip. 

%
\begin{Rcode}
<<keep.source=true>>=
E <- editmatrix(c(
    "x + y == z",
    "x > 0",
    "y > 0",
    "z > 0"))

dat <- data.frame(
    x = c(1,-1,1),
    y = c(-1,1,1),
    z = c(2,0,2))

# localize all errors in the data using mip
localizeErrors(E,dat, method="mip")
@
\caption{Localizing errors in a data.frame using {\tt method="mip"}}
\label{RlocalizeErrors}
\end{Rcode}

The default boundary conditions used in {\tt localizeErrors} use ${\rm u_i} = 1000 \cdot x^0_i$ and ${\rm l_i} = -1000 \cdot x^0_i$.

\section{Categorical data errors}

\label{sec:catdataerror}
A categorical record $\bf v$  with reported values $({v^0_1,\dots,v^0_m)}$ has the following $n$ constraints:
\begin{equation}e^i = 
  \begin{array}{rl}
    \label{eq:catedit}
    \mbox{{\bf if }} & v_j \in F^i_j \mbox{ for }j = 1, \ldots, m \\
    \mbox{ {\bf then}} & \mbox{FALSE}
  \end{array}
\end{equation}
with $F^i_j \subseteq D_j$ where $D_j$ is the possible set of categories $\{1, \ldots, k\}$ for each $v_j$ and $i = 1 \ldots n$ the number of edits.

It can easily be checked with {\sf editrules} if $\bf v$ violates any of these constraints. If this is the
case, the task is to find the minimal (weighted) number of adjustments to the reported values such that it
complies to the edits. Internally {\sf editrules} uses an {\sf editarray} object which is described in 
detail in \cite{loo:2011b}. In this paper we use a different, but equivalent, representation to allow for 
an easy conversion to a mixed integer program: {\sf cateditmatrix}.

A record of $m$ categorical variables can be written as an element
of the cartesian product space $D$:
\begin{equation}
  \label{eq:Domain}
  D = D_1\times D_2\times\cdots\times D_m,
\end{equation}
where each $D_j$ is the set of possible categories for variable $j$.

The number of categories for variable $j$ is labeled $d_j$ while the
total number of categories is labeled $d$, given by
\begin{equation}
  d=\sum_{j=1}^n d_j
\end{equation}
Categorical record $\bf v$ can be written as in this space as
\begin{equation}
  \begin{array}{rcl}
    {\bf \check{v}} & = & \oplus^m_{j=1} (\check{v}_{j1}, \ldots, \check{v}_{j{d_j}}) \\
                    & = & (\check{v}_{1 1}, \cdots, \check{v}_{1 {d_1}},
                          \cdots, \check{v}_{m 1}, \cdots,     \check{v}_{m {d_m}})
  \end{array}
\end{equation}

\begin{equation}
  \mbox{with }
  \check{v}_{jk} 
  =  \left\{ 
  \begin{array}{ll}
         0 & \mbox{if } v_j \not= k \\
         1 & \mbox{if } v_j = k
  \end{array} \right.
\end{equation}

Equation (\ref{eq:catedit}) can be written in the following form:
\begin{eqnarray}
     e^i  & = & \lnot \bigwedge_{j=1}^m v_j \in F^i_j = \bigvee_{j=1}^m\lnot (v_j \in {F^i_j}) \\
          & = &  \bigvee_{j=1}^m v_j \not\in {F^i_j} = \bigvee_{j=1}^m v_j \in T^i_j
\end{eqnarray}
with $T^i_j = D_j \setminus F^i_j$. 
This means that edit $e^i$ is satisfied if at least one $v_j \in T^i_j$. $e^i$ can therefore be written as:

\begin{equation} \label{eq:tmip}
  \sum^m_{j=1} \left(\sum^{d_j}_{k=1} t^i_{jk} \cdot \check{v}_{jk}\right) \geq 1
\end{equation}

\begin{equation} \label{eq:aijk}
  \mbox{with }
  t^i_{jk} = \left\{ 
  \begin{array}{ll}
         0 & \mbox{if } k \not\in T^i_j\\
         1 & \mbox{if } k \in T^i_j
  \end{array} \right. 
\end{equation}
These edits are (usually) valid for all records of a data set. Note that equation (\ref{eq:catmip}) is in 
a form to be used in a mixed integer program where $\check{v}_{jk}$ are integer variables.

For each $v_j$ its categories should exclude each other, so the following constraint must hold:
\begin{equation}
   \left(\sum^{d_j}_{k=1} \check{v}_{jk}\right) \leq 1
\end{equation}

We introduce for each $v_j$ a binary variable $\Delta_j \in {0,1}$:
\begin{equation} \label{eq:catdelta}
  \Delta_j = \left\{ 
  \begin{array}{ll}
         0 & \mbox{if $v_j = v^0_j$}\\
         1 & \mbox{if $v_j \neq v^0_j$}.
  \end{array} \right. 
\end{equation}

where $v^0_j$ is the reported value for $v_i$. We now add the following edit to the edit set:
\begin{equation}
   \check{v}_{jk^0_j}  =  1 - \Delta_j \mbox{ with } k^0_j = v^0_j
\end{equation}
It can be easily checked that if $\Delta_j = 0$ $\check{v}_{jk^0_j} = 1$, meaning that the reported value 
$v^0_j$ is assumed correct. If $\Delta_j = 1$, $\check{v}_{jk^0_j} = 0$, meaning that $v_j$ should have a different value.

The categorical error localization problem now can be written as:

{\textrm Minimize} $\sum^m_{j=1} {\rm w_j}\Delta_j$, with:
\begin{equation}
\label{eq:catmip}
\begin{array}{rcrcl}
  \sum^m_{j=1} \left(\sum^{d_j}_{k=1} t^1_{jk} \cdot \check{v}_{jk}\right)&& &\geq& 1 \\
  \ldots                 &&                  &\ldots& \ldots  \\
  \sum^m_{j=1} \left(\sum^{d_j}_{k=1} t^n_{jk} \cdot \check{v}_{jk}\right)&& &\geq& 1 \\
    \sum^{d_1}_{k=1} \check{v}_{1k} && & \leq & 1 \\
    \check{v}_{1k^0_1} & +    & \Delta_1 & =    & 1 \\
    \ldots  & & \ldots          &       & \ldots \\
    \sum^{d_m}_{k=1} \check{v}_{mk} && & \leq & 1 \\
    \check{v}_{mk^0_m} & + & \Delta_m & =    & 1 \\
\end{array}
\end{equation}

Note that parts of equation (\ref{eq:tmip}) can be written in a negated form:
\begin{equation} \label{eq:fmip}
  \mbox{ if } T^i_j \neq \emptyset \mbox{ then } \sum^{d_j}_{k=1} t^i_{jk} \cdot \check{v}_{jk}  = 1 - \left(\sum^{d_j}_{k=1} f^i_{jk} \cdot \check{v}_{jk} \right) 
\end{equation}

\begin{equation} \label{eq:aijk}
  \mbox{with }
  f^i_{jk} = \left\{ 
  \begin{array}{ll}
         0 & \mbox{if } k \not\in F^i_j\\
         1 & \mbox{if } k \in F^i_j
  \end{array} \right. 
\end{equation}

\subsection{The {\sf cateditmatrix} object}
To create a mip formulation for the categorical error localization problem, {\sf editrules} uses
internally the {\sf cateditmatrix} object. {\sf cateditmatrix} is an {\sf editmatrix} object, which is described in \cite{jonge:2011}, but it "remembers" that it is categorical. 

%
\begin{Rcode}
<<keep.source=true>>=
E <- cateditmatrix( 
       expression( gender %in% c("male", "female")
                 , if (pregnant) gender == "female"
                 )
                  )
as.data.frame(E)
getAb(E)
@
\caption{Using the {\sf cateditmatrix} object}
\label{R:cateditmatrix}
\end{Rcode}
Figure \ref{R:cateditmatrix} shows an example for the use of {\sf cateditmatrix}. It also shows that categorical edits can be written in the form of a linear constraint to be used in an mixed integer problem solver. 
{\sf cateditmatrix} can coerce an {\sf editarray}. This method can be called explicitly by a user, but it 
it will be called implicitly in {\sf localizeErrors} using {\tt method="mip"}.
An example is shown in figure \ref{R:localizeCat}

%
\begin{Rcode}
<<keep.source=true>>=
dat <- data.frame(gender="male", pregnant=TRUE)
localizeErrors(E,dat, method="mip")
@
\caption{Using {\sf localizeErrors} method with categorical data}
\label{R:localizeCat}
\end{Rcode}

\section{Discussion}

Is a usefull addition to {\tt editrules}, finds quickly solutions to error localization  problems with 
hundreds to thousands of variables. 

Solutions given by current lp solvers can be numerical unstable, which may result in a false positive 
or a false negative solution. Luckily {\tt editrules} contains {\tt substValue} and {\tt isFeasible} 
that can be used together to check the validity of a solution. Furthermore several heuristics can be 
used to increase the numerical stability by using smaller boundaries for the variables.

\subsection{Comparison to {\tt backtracker}}
errorLocalizer is more complete, offers a more complete tool box for finding an optimal solution.
It can also find more equivalent solutions, which is not possible or difficult with MIP solvers.

\bibliographystyle{chicago}
\bibliography{editrules}

\end{document}
